{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-308/train.csv\").dropna(how='all')\n",
    "\n",
    "df.info()\n",
    "df = df.dropna()\n",
    "test_df = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-308/test.csv\").dropna(how='all').drop(columns=['ID'])\n",
    "\n",
    "df.info()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.boxplot(df)\n",
    "plt.title(\"Анализ выбросов\", fontsize=16, pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64caae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[abs(df['RiskScore']) < 200].drop(columns=['ApplicationDate'])\n",
    "test_df = test_df.drop(columns=['ApplicationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for column in df.select_dtypes(include=['object']).columns.tolist():\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "for column in test_df.select_dtypes(include=['object']).columns.tolist():\n",
    "    le = LabelEncoder()\n",
    "    test_df[column] = le.fit_transform(test_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624813e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test_df.select_dtypes(include=['number']).columns.tolist()\n",
    "for col in test_df.select_dtypes(include=['number']).columns.tolist():\n",
    "  df[col + '_cube'] = df[col] ** 3.1\n",
    "  df[col + '_div_by_cube'] = df[col] ** (1/3)\n",
    "  test_df[col + '_cube'] = test_df[col] ** 3.1\n",
    "  test_df[col + '_div_by_cube'] = test_df[col] ** (1/3)\n",
    "\n",
    "for ncol1 in range(len(cols) - 5):\n",
    "  for ncol2 in range(ncol1 + 1, len(cols) - 5):\n",
    "    col1 = cols[ncol1]\n",
    "    col2 = cols[ncol2]\n",
    "    df[col1 + '_' + col2] = df[col1] * df[col2]\n",
    "    test_df[col1 + '_' + col2] = test_df[col1] * test_df[col2]\n",
    "\n",
    "def create_financial_stability_features(df):\n",
    "\n",
    "    # Коэффициент финансовой независимости\n",
    "    df['FinancialIndependenceRatio'] = (df['NetWorth'] + 1) / (df['TotalLiabilities'] + 1)\n",
    "\n",
    "    # Покрытие долгов активами\n",
    "    df['AssetDebtCoverage'] = df['TotalAssets'] / (df['TotalLiabilities'] + 1)\n",
    "\n",
    "    # \"Финансовая подушка\" - сбережения относительно дохода\n",
    "    df['FinancialCushion'] = (df['SavingsAccountBalance'] + df['CheckingAccountBalance']) / \\\n",
    "                            (df['AnnualIncome'] / 12 + 1)\n",
    "\n",
    "    # Платежная способность (сколько месяцев можно жить на сбережения)\n",
    "    df['MonthsOfSavings'] = (df['SavingsAccountBalance'] + df['CheckingAccountBalance']) / \\\n",
    "                           (df['MonthlyDebtPayments'] + 1)\n",
    "\n",
    "    # Риск ликвидности\n",
    "    df['LiquidityRisk'] = (df['MonthlyDebtPayments'] + df['MonthlyLoanPayment']) / \\\n",
    "                         (df['MonthlyIncome'] + 1)\n",
    "\n",
    "    # Чистый денежный поток\n",
    "    df['NetCashFlow'] = df['MonthlyIncome'] - df['MonthlyDebtPayments'] - df['MonthlyLoanPayment']\n",
    "    df['CashFlowAdequacy'] = df['NetCashFlow'] / (df['MonthlyLoanPayment'] + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_debt_risk_features(df):\n",
    "\n",
    "    # Общая долговая нагрузка (все долги)\n",
    "    df['TotalDebtBurden'] = df['MonthlyDebtPayments'] + df['MonthlyLoanPayment']\n",
    "    df['TotalDebtToIncome'] = df['TotalDebtBurden'] / (df['MonthlyIncome'] + 1)\n",
    "\n",
    "    # \"Долговая ловушка\" - отношение долгов к активам\n",
    "    df['DebtTrapRisk'] = df['TotalLiabilities'] / (df['TotalAssets'] + 1)\n",
    "\n",
    "    # Риск дефолта на основе CreditScore и долгов\n",
    "    df['DefaultRiskScore'] = ((850 - df['CreditScore']) / 850) * df['DebtToIncomeRatio']\n",
    "\n",
    "    # Нагрузка от нового кредита\n",
    "    df['NewLoanBurden'] = df['MonthlyLoanPayment'] / (df['MonthlyIncome'] + 1)\n",
    "\n",
    "    # Соотношение кредита к доходу\n",
    "    df['LoanToIncomeAnnual'] = df['LoanAmount'] / (df['AnnualIncome'] + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_comprehensive_binning_features(df):\n",
    "\n",
    "    df_enhanced = df.copy()\n",
    "\n",
    "    df_enhanced['DebtToIncome_Binned'] = pd.cut(\n",
    "        df_enhanced['DebtToIncomeRatio'],\n",
    "        bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Отношение кредита к доходу\n",
    "    loan_to_income = df_enhanced['LoanAmount'] / (df_enhanced['AnnualIncome'] + 1)\n",
    "    df_enhanced['LoanToIncome_Binned'] = pd.cut(\n",
    "        loan_to_income,\n",
    "        bins=[0, 0.5, 1.0, 1.5, 2.0, 10],\n",
    "        labels=[1, 2, 3, 4, 5]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Уровень сбережений\n",
    "    savings_ratio = df_enhanced['SavingsAccountBalance'] / (df_enhanced['AnnualIncome'] + 1)\n",
    "    df_enhanced['SavingsRatio_Binned'] = pd.cut(\n",
    "        savings_ratio,\n",
    "        bins=[0, 0.1, 0.25, 0.5, 1.0, 100],\n",
    "        labels=[5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Покрытие долгов активами\n",
    "    asset_coverage = df_enhanced['TotalAssets'] / (df_enhanced['TotalLiabilities'] + 1)\n",
    "    df_enhanced['AssetCoverage_Binned'] = pd.cut(\n",
    "        asset_coverage,\n",
    "        bins=[0, 0.5, 1.0, 2.0, 5.0, 1000],\n",
    "        labels=[5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Чистая стоимость относительно дохода\n",
    "    networth_ratio = df_enhanced['NetWorth'] / (df_enhanced['AnnualIncome'] + 1)\n",
    "    df_enhanced['NetWorthRatio_Binned'] = pd.cut(\n",
    "        networth_ratio,\n",
    "        bins=[-1000, 0, 0.5, 1.0, 2.0, 1000],\n",
    "        labels=[5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Использование кредитного лимита\n",
    "    df_enhanced['CreditUtilization_Binned'] = pd.cut(\n",
    "        df_enhanced['CreditCardUtilizationRate'],\n",
    "        bins=[0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "        labels=[1, 2, 3, 4, 5, 6]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Количество кредитных линий\n",
    "    df_enhanced['CreditLines_Binned'] = pd.cut(\n",
    "        df_enhanced['NumberOfOpenCreditLines'],\n",
    "        bins=[0, 1, 3, 5, 7, 10, 100],\n",
    "        labels=[1, 2, 3, 4, 5, 6]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    # Частота кредитных запросов\n",
    "    df_enhanced['CreditInquiries_Binned'] = pd.cut(\n",
    "        df_enhanced['NumberOfCreditInquiries'],\n",
    "        bins=[-1, 0, 1, 2, 3, 5, 100],\n",
    "        labels=[1, 2, 3, 4, 5, 6]\n",
    "    ).astype(float).fillna(2)\n",
    "\n",
    "    # Длительность кредитной истории\n",
    "    df_enhanced['CreditHistoryLength_Binned'] = pd.cut(\n",
    "        df_enhanced['LengthOfCreditHistory'],\n",
    "        bins=[0, 2, 5, 7, 10, 15, 100],\n",
    "        labels=[6, 5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(4)\n",
    "\n",
    "    # Качество платежной истории\n",
    "    payment_quality = df_enhanced['PaymentHistory'] / (df_enhanced['LengthOfCreditHistory'] + 1)\n",
    "    df_enhanced['PaymentQuality_Binned'] = pd.cut(\n",
    "        payment_quality,\n",
    "        bins=[0, 0.5, 0.7, 0.85, 0.95, 1.0],\n",
    "        labels=[5, 4, 3, 2, 1]\n",
    "    ).astype(float).fillna(3)\n",
    "\n",
    "    return df_enhanced\n",
    "\n",
    "df = add_comprehensive_binning_features(create_debt_risk_features(create_financial_stability_features(df)))\n",
    "test_df = add_comprehensive_binning_features(create_debt_risk_features(create_financial_stability_features(test_df)))\n",
    "\n",
    "def add_log_transformations(df, test_df):\n",
    "    df_log = df.copy()\n",
    "    test_log = test_df.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        if (df[col] > 0).all():\n",
    "            df_log[f'Log_{col}'] = np.log1p(df[col])\n",
    "            test_log[f'Log_{col}'] = np.log1p(test_df[col])\n",
    "        else:\n",
    "            min_val = df[col].min()\n",
    "            if min_val <= 0:\n",
    "                shift = abs(min_val) + 1\n",
    "                df_log[f'Log_{col}'] = np.log1p(df[col] + shift)\n",
    "                test_log[f'Log_{col}'] = np.log1p(test_df[col] + shift)\n",
    "\n",
    "    return df_log, test_log\n",
    "\n",
    "df, test_df = add_log_transformations(df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724169cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "correlation_with_target = df.corr()['RiskScore'].abs().sort_values(ascending=False)\n",
    "print(\"Корреляция с RiskScore:\")\n",
    "print(correlation_with_target.head(15))\n",
    "\n",
    "low_corr_features = correlation_with_target[correlation_with_target < 0.05].index.tolist()\n",
    "print(len(low_corr_features))\n",
    "df = df.drop(columns=low_corr_features)\n",
    "test_df = test_df.drop(columns=low_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_correlated_features_to_remove(df, corr_threshold=0.9, target_corr_threshold=0.08, target_column='RiskScore'):\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    target_correlations = corr_matrix[target_column].drop(target_column)\n",
    "\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "    )\n",
    "\n",
    "    columns_to_remove = set()\n",
    "\n",
    "    for col in upper_triangle.columns:\n",
    "        if col == target_column:\n",
    "            continue\n",
    "\n",
    "        high_corr_with = upper_triangle[col][upper_triangle[col] > corr_threshold]\n",
    "\n",
    "        for correlated_col in high_corr_with.index:\n",
    "            if correlated_col == target_column:\n",
    "                continue\n",
    "\n",
    "            col_target_corr = target_correlations[col]\n",
    "            correlated_col_target_corr = target_correlations[correlated_col]\n",
    "\n",
    "            if col_target_corr < target_corr_threshold and correlated_col_target_corr < target_corr_threshold:\n",
    "                if col_target_corr < correlated_col_target_corr:\n",
    "                    columns_to_remove.add(col)\n",
    "                else:\n",
    "                    columns_to_remove.add(correlated_col)\n",
    "            elif col_target_corr < target_corr_threshold and correlated_col_target_corr >= target_corr_threshold:\n",
    "                columns_to_remove.add(col)\n",
    "            elif col_target_corr >= target_corr_threshold and correlated_col_target_corr < target_corr_threshold:\n",
    "                columns_to_remove.add(correlated_col)\n",
    "\n",
    "    return list(columns_to_remove)\n",
    "\n",
    "columns_to_remove = get_highly_correlated_features_to_remove(\n",
    "    df,\n",
    "    corr_threshold=0.98\n",
    ")\n",
    "\n",
    "print(f\"Признаки для удаления: {columns_to_remove}\")\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "test_df = test_df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_cols_to_scale = [col for col in df.columns if col != 'RiskScore']\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[numeric_cols_to_scale] = scaler.fit_transform(df[numeric_cols_to_scale])\n",
    "df = df_standardized\n",
    "\n",
    "test_df_standardized = test_df.copy()\n",
    "test_df_standardized[numeric_cols_to_scale] = scaler.transform(test_df[numeric_cols_to_scale])\n",
    "test_df = test_df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbf06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop('RiskScore', axis=1)\n",
    "y = df['RiskScore']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "print(\"КАЧЕСТВО МОДЕЛИ НА ОБУЧАЮЩИХ ДАННЫХ:\")\n",
    "print(f\"R² score: {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_train, y_train_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_train_pred)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"КАЧЕСТВО МОДЕЛИ НА ВАЛИДАЦИОННЫХ ДАННЫХ:\")\n",
    "print(f\"R² score: {r2_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_val, y_val_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_val, y_val_pred)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_val, y_val_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648493a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ty_pred = model.predict(test_df)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'ID': range(len(ty_pred)),\n",
    "    'RiskScore': ty_pred\n",
    "})\n",
    "\n",
    "\n",
    "y_test = pd.read_csv(\"/kaggle/input/mai-ml-lab-1-308/ex.csv\").drop(columns=['ID'])\n",
    "print(f\"R² score: {r2_score(y_test, ty_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, ty_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, ty_pred)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, ty_pred):.4f}\")\n",
    "\n",
    "result.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
